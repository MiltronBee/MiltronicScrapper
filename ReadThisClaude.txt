## üéØ GOAL

Assemble a high-fidelity **text corpus** reflecting real-world **Mexican Spanish** in its full range:

* Formal (legal, academic, journalistic)
* Informal (spoken, slang, social media)
* Mixed (code-switching, anglicisms, phonetic drift)

Format: **JSONL** with clean sentence-level units:

```json
{"text": "¬øY t√∫ qu√© pedo con el proyecto ese del backend?"}
```

---

## üî£ STRUCTURE

| Tier | Register            | Source Domains                     | Priority |
| ---- | ------------------- | ---------------------------------- | -------- |
| T1   | Academic/Formal     | UNAM repos, SCJN, SEP, CONACyT     | High     |
| T2   | Legal/Parliamentary | Diario de los Debates, SCJN docs   | High     |
| T3   | News                | Proceso, El Universal, La Jornada  | Medium   |
| T4   | Spoken/Dialogue     | CIEMPIESS `normalized_text`, radio | High     |
| T5   | Slang/Street        | Reddit MX, Twitter, WhatsApp dumps | Medium   |
| T6   | Fiction/Subtitles   | Netflix subs, TV scripts, books    | Medium   |
| T7   | Code-mixed Tech     | Dev forums, StackOverflow, blogs   | Medium   |

---

## ‚öíÔ∏è TOOLING

* **Scraping**: `requests`, `BeautifulSoup`, `trafilatura`, `newspaper3k`, `scrapy`
* **Cleaning**: `ftfy`, `unidecode`, `langdetect`, `re`, `spaCy` (`es_core_news_sm`)
* **Chunking**: Sentence segmentation via `spaCy` or `es_sent_tokenize`
* **Deduplication**: `datasketch` (MinHash), or locality-sensitive hashing
* **Export**: Line-by-line `.jsonl` ‚Äî ready for `transformers` or `Axolotl`

---

## üß™ PHASE 1 SOURCES TO EXTRACT IMMEDIATELY

* ‚úÖ `ciempiess/*` ‚Äì extract `normalized_text` fields
* ‚úÖ UNAM Repositorio Institucional: [https://repositorio.unam.mx/](https://repositorio.unam.mx/)
* ‚úÖ SCJN PDFs ‚Üí parsed text via `pdfminer.six` or `PyMuPDF`
* ‚úÖ SEP publications (books, civics, textbooks): [https://libros.conaliteg.gob.mx/](https://libros.conaliteg.gob.mx/)
* ‚úÖ Diario de los Debates: [https://cronica.diputados.gob.mx/](https://cronica.diputados.gob.mx/)
* ‚úÖ Proceso: [https://www.proceso.com.mx/](https://www.proceso.com.mx/)
* ‚úÖ TV scripts/subs: OpenSubtitles.org (filter: Mexican Spanish)

---

## üì¶ OUTPUT

* Single `.jsonl` file or sharded files:
  `mx_corpus_llm_v1_train.jsonl`
  `mx_corpus_llm_v1_eval.jsonl`

Each line:

```json
{"text": "La Suprema Corte resolvi√≥ en sesi√≥n p√∫blica que el amparo es procedente."}
```

---

## ‚úÖ ACTION PLAN

1. **Set up repo**
2. **Scraper modules** per source
3. **Pipeline**: scrape ‚Üí clean ‚Üí chunk ‚Üí dedup ‚Üí JSONL
4. **Manual audit samples** per source (100‚Äì200 lines)
5. **Corpus size target**:

   * Min: 500k examples
   * Ideal: 2M‚Äì4M examples (\~1B tokens)
